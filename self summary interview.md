-------------------

## golang

### go gc 

开始: 标记清楚法, 每次清理垃圾时都要STW对性能影响较大

三色标记法: 由黑色, 灰色, 白色组成, 在开始gc时, 所有对象为白色, 扫描由堆栈根节点出发扫描一层对象, 将其标为灰色, 后面gc只扫描灰色对象, 将已扫描的灰色对象置为黑色, 直到没有灰色对象, 就清除白色垃圾

​	引发的问题: 当一个灰色对象删除了一个白色对象的引用, 而黑色对象引用了这个白色对象, 那这个白色对象就会被清除

​	为解决这个问题: 引入强弱三色不变式

​	强三色不变式: 不存在黑色对象引用到白色对象的指针

​		插入屏障(栈上不使用): 堆上黑色对象引用白色对象时, 将白色对象置灰, 而栈上在gc结束之前使用stw重新扫描栈上对象

​	弱三色不变式: 被黑色对象引用的白色对象的上游有灰色对象保护

​		删除屏障: 当删除对象时, 如果对象为灰色或白色则置灰, 当轮不删除(gc效率低)

三色标记与混合屏障: 

1. 将栈上可达对象均置为黑色, 后续新建的栈上对象均为黑色
2. 后续删除与被添加的对象均标记为灰色









### go gmp

g: golang 语言层面的协程

m: mechine 对应一个内核线程

p: processer 处理队列

全局队列

通过 gomaxprocs 控制 p 的数量, 也是程序最高并行量

开始的gm模型: 多个 m 抢占一个全局 goroutine 队列(激烈的锁竞争, 性能低下)

**设计策略:**

- 复用线程:
    - working stealing 机制: 当一个 p 队列没有goroutine时首先偷取其余队列的 g(偷后一半), 偷不到从全局队列拿(但自旋线程首先从全局队列去取)
    - hand off 机制: 当 g 阻塞时, g 会与 m 绑定, m 与 p 解绑, p 会寻找空闲 m
- 并行: 设置 gomaxprocs 控制 p 的数量
- 抢占: 每个 g 最多运行 10ms



从阻塞状态恢复的 m, 会试图与 原始的 p 尝试绑定失败从空闲 p 队列获取, 成功允许 g, 失败将 g 加入全局队列



每个 m 都有一个 g0, 其中 g0 只用于调度

每个程序都会有一个 m0, m0 负责启动第一个 g, 后续就和其余 m 相同









### go func()  调度流程

- 通过 go func() 新建一个 goroutine, 新建的 g 会根据局部性优先加入本地 p 队列, 如果本地 p 队列已满, 打乱 p 前一半顺序后与 新建 g 一起加入全局队列
- 在 p 队列重复调度, 直到 g 完成
- 状态: 调度 -> 执行/阻塞 -> 销毁 -> 再次进入 p 本地队列













### go slice array













### go map







### go channel

csp 模型: 不通过共享内存来实现通信, 而是通过通信来实现通信

- 环形数组, recvx, sendx
- sendq, recvq 用于存放读取和写入goroutine的等待队列, 当channel可读可写时, 会按照链表顺序依次唤醒recvq与sendq中的goroutine
- lock: 每次操作都没加锁











### jwt 数据结构

- header: 标识为 jwt

- ##### Payload: 自定义内容

- ##### Signature: 有Payload内容+自定义秘钥通过header的加密算法加密得到











### append() 原理

https://blog.csdn.net/e2788666/article/details/130611004

https://tonybai.com/2020/12/17/where-is-the-source-of-builtin-functions/

当扩容时, slice的底层数据会发生变化, 其长度和cap都会变化, 自然就会创建一个新的slice, 如果扩容后原始数组不存在对象引用就会被gc回收

当不扩容时, slice结构体中len会发生变化, 所以slice会改变, 所以也会返回一个新的slice





### make() 和 new() 区别

new() : 会为类型分配一份内存空间, 并将值置为零值

make() : 同样用于内存分配(常用于 chan, map, slice) 

go 编译器会尽量将对象分配到栈上, 如果变量未逃逸, 就在栈上分配, 否则在堆上分配, 如果对象过大, 会分配到堆上



### 内存逃逸

- 如果超出对象的指针生命周期, 会逃逸到堆(使用指针变量, 引用对象等)
- 栈对象指针不能指向堆对象



逃逸分析: `go build -gcflags '-m -m -l'`





### go 引用类型

储存的不是数据本身而是指向底层数据结构的指针

例如: slice, map, channel















### rpc 协议

rpc 是一种远程过程调度协议, 他包含传输协议和序列化协议, 他不存在具体的协议

传输协议: tcp, udp, http 都可作为底层传输协议

序列化协议: protobuf, xml, thrift等

rpc 通过函数调用, http 通过url调用实现

grpc 的rpc是通过tcp加http







### rpc 是如何建立连接的

https://juejin.cn/post/7304268951298490418

1. 建立连接
2. 按网络协议通信
3. 服务端收到客服端请求然后处理 (BIO, NIO, AIO)
4. 按序列化结果返回给客服端

#### 建立连接

##### 1.http 通信

- 建立http连接, 依赖于传输层tcp连接
- 发送请求
- 接受请求
- 返回响应
- 断开连接



##### 2. socket 通信

- 服务器监听
- 客户端请求
- 服务器确认
- 数据传输















----------------------

## kubernetes

### etcd









### k8s 优势









### iptables 和 ipvs 原理与区别





ipvs 用到的是 iptables 的扩展 ipset, 不是直接调用 iptables 来生成规则链, iptable 规则链是一种带线性的数据结构, 而 ipset 使用的是更高效的数据哈希表, 因此当规则很多时能更有效的查找与匹配

ipvs 支持多种负载均衡算法, 支持服务器健康检测与连接重试











### pod 一直 crash

https://www.cnblogs.com/alisystemsoftware/p/16919263.html

describe 查看 pod event

- 初始化失败
- livenessprobe 失败
- 容器退出: 查看容器日志







---------------------

## istio

https://www.cnblogs.com/BlogNetSpace/p/17325923.html

### 如何注入 sidecar

在命名空间设置 istio-injection=enabled

istio 会注入两个容器, istio-init, 和 istio-proxy

istio-init: init container 用于设置 iptables 规则，以便将入站/出站流量通过 sidecar 代理

istio-proxy(envoy): 代理容器出入站流量



自动注入: 依赖 Mutating Admission Webhook

手动注入: 需要手写yaml配置init和siedcar容器







### envoy 如何接管 pod 中容器的流量





















----------------------

## 操作系统





### 中断与异常

中断: cpu对系统发生某事件时的一种响应, cpu暂停正在执行的程序保留现场后去执行中断处理程序, 执行后恢复原程序的断点处继续执行

​	外中断: 通常有外部硬件设备引发

​	内中断: 就是异常, 指针越界等

中断是让操作系统内核夺回cpu的唯一途径





### 介绍进程和线程协程, 区别

进程: 是操作系统资源分配的最小单位, 进程有控制块, 程序段和数据段组成

​	控制块: pcb 保存进程运行期间相关数据, 是进程的唯一标识

​	程序段: 是程序能够调度到cpu运行的代码段

​	数据段: 储存程序运行期间的相关数据

线程: 是cpu调度和执行的最小单位, 一个进程可以有多个线程, 且共享进程资源, 每个线程都有自己的运行栈与程序计数器

协程: 是用户态轻量级线程, 一个线程可以有多个协程, 协程拥有自己的寄存器上下文与栈, 协程相比线程占用资源少, 由用户调度, 不主动释放

区别:

切换: 线程的上下文切换远远快于进程(内核栈与硬件上下文)

拥有资源: 每个进程都有操作系统分配的独立虚拟空间, 而同一个进程下的线程共享进程资源

系统开销: 进程的创建与销毁开销也远远大于线程的开销



进程切换耗时: 进程切换需要切换虚拟内存, 那页表也会切换, 那 tlb 缓存中页表也会失效, 而线程切换就无需设计页表切换







### 零拷贝

是为了减少cpu数据拷贝

传统数据拷贝需要将文件通过dma数据拷贝到内核缓存, 在从内核缓存拷贝到用户缓存, 要写时, 要将用户缓存数据拷贝到内核缓存, 在通过dma拷贝到文件或socket

- mmap : 直接将内核缓存映射到用户缓存

- sendfile : 只需两次dma数据拷贝, 文件数据dma拷贝内核, 内核直接在dma拷贝到另外的文件

- splice : 在内核缓存区建立了一个管道, 该管道可与用户缓存通信, 负责内核缓存区数据交换
- tee : 







### 僵尸进程, 孤儿进程

孤儿进程: 当父进程结束, 子进程未结束, 子进程会被init进程接管

僵尸进程: 父进程未处理子进程退出的状态信息, 那子进程的文件描述符, 依然存在于系统, 也就会消耗系统资源

处理子进程退出信号, 杀死父进程, 重启





### 虚拟内存

为防止多进程运行导致内存地址冲突, 而引入虚拟内存控制, 使进程以为独占内存空间, 进程访问虚拟地址通过cpu的mmu将其转换为物理地址

操作系统通过分段与分页机制进行虚拟地址与物理地址的转换

​	分段: 程序需要100M则会有100M与之对应的物理内存

​	分页(多级与tpb加速): 将虚拟内存与物理内存分为大小相同的页



分布:

​	32位: 4G, 64为: 用到低48位

​	分为, 用户空间与内核空间

- 代码段  -  只读
- 数据段
- bss 段: 存放程序中未初始化的全局变量与静态变量
- 堆: 存放用户动态申请的内存
- 文件映射段(共享区): 共享内存等共享资源
- 栈: 用于存储函数的临时变量





### 堆栈区别

操作系统为防止多进程运行造成的内存冲突, 引入了虚拟内存

栈用来存储程序中临时创建的临时变量, 每个函数会将参数入栈, 结束后会将返回值入栈, 每次开辟一个新的函数时会开辟一个新的栈, 当递归深时, 可能导致栈溢出, 且栈容量有系统分配且固定, 每个线程都有一个固定大小的栈空间, 每个线程的栈空间独立, 所以线程安全



堆: 用于存储用户动态申请分配的空间, 可以扩容, 但是容易产生内存碎片, 在整理内存碎片时效率较低, 如果申请的内存没有清理发生内存泄漏, 堆内存所有线程共享, 多线程可能产生问题









### 进程调度

- 先来先服务
- 短作业优先
- 最短剩余时间优先
- 时间片轮转: 注意时间片大小
- 高响应比调度
- 最高优先级调度: 为进程分配优先级, 等待时间越长优先级越高
- 多级反馈队列调度: 多个队列每个队列优先级从高到低





### 进程状态

- 创建

- 就绪: 所需系统资源充足, 等待cpu时间片
- 运行
- 阻塞: i/o 请求
- 结束





### 并发和并行

并发: 在一个cpu时, 就需要把cpu划分为不同的时间片, 将时间片分给不同的线程运行, 进而做到宏观上并行, 微观并发

并行: 在多个cpu时, 可以做个多个线程同时执行, 线程互不抢占cpu资源





### 多进程多线程模型

单进程: 所有进程只有线性处理, 当前面的进程阻塞时, 后续线程同样会阻塞

多进程: 一个cpu来看, 当一个进程发送阻塞时, cpu会立即切换到其他进程, 并且可根据相应的调度算法确保每个进程可被分配到cpu时间片, 也就可做到宏观上多个进程同时进行

​	-> 可引入内核线程, 用户态线程

协程调度器: 也可理解为一个用户态线程, 会绑定一个内核线程, 用于调度协程

内核线程 : 协程(协程需要主动释放控制权)

1:n : 会出现当一个协程阻塞时, 会阻塞其余后续协程的调度

1:1 : 协程的创建、删除和切换的代价都由CPU完成，有点略显昂贵了

m:n : 多个内核线程绑定一个协程调度器, 关键在于协程调度器的设计, 设计复杂

另外就是 golang 的gmp模型













### 进程间的通信方式

- 管道: 匿名管道和命名管道  (半双工 - 单向通信)
    - 匿名管道: 当创建一个匿名管道时会在内核缓存区开辟一块空间, 往往用于具有亲密关系的进程间通信
    - 命名管道: 在磁盘中真实存在的一个文件, 可以实现
- 信号: 异步通信机制, 用于通知进程某一时间已发生
- 信号量: 是一个计数器常作为锁机制与共享内存结合使用, 用来控制进程线程对临界资源的访问
- 消息队列: 是保存在内核中的消息链表, 按照消息类型传递, 较高可靠性与稳定性, 消息体存在长度限制
- 共享内存: 有一个进程创建一段能由其他进程所访问的内存, 对共享内存的调用无需陷入内核态与系统, 提高了通信效率
- socket
- 文件











### 进程间的同步方式

- 临界区  --  只允许同时有一个进程进入临界区

- 互斥量
- 信号量
- 事件







### 线程间的同步方式

线程间同步是让线程有序的访问进程的共享资源

- 互斥锁
- 自旋锁
- 读写锁
- 条件变量: 通常与互斥量配合, 先对互斥量加锁在判断条件
- 屏障: 用于协调多个线程并行工作的同步机制, 屏障允许每个线程等待直到所有合作线程都到达, 后继续执行
- 信号量: 









### 互斥锁, 自旋锁和读写锁

互斥锁: 保证同一时刻只有一个资源进入临界区, 也叫阻塞锁, 当互斥锁被占有时, 其他线程想要访问临界资源会发生阻塞(临界资源访问时间长)

自旋锁: 也叫非阻塞锁, 当自旋锁资源被占用时, 其余线程想要访问临界资源时会占用cpu资源循环检测(临界资源访问时间短, 且竞争不激烈)

读写锁: 允许多个线程同时对共享数据进行读操作, 但仅允许一个线程同时写共享数据(多读少写)





### 乐观锁与悲观锁

- 悲观锁: 互斥锁, 自旋锁和读写锁
- 乐观锁: 















### 分页和分段















### 页面替换算法

当进程运行时访问的页面不在内存时就产生一个缺页中断, 请求系统把也调度到物理空间, 若内存中无空间就会发生页面调度

- 最佳置换算法: 置换未来时间最长不会调度的页面, (无法实现)
- 先进先出: 
- 最近最久未使用(lru)
- 最不常用置换(lfu): 每个页面带有一个计数器, 置换计数最低的页面
- 时间置换算法: 环形链表将所有访问位置为 1, 依次扫描, 将扫描过程中访问位为 1的置为 0, 知道找到第一个访问位为 0的页面







### 内存碎片



















### 磁盘调度算法







### 死锁

- 互斥: 同一个资源只能有一个线程占有
- 不可剥夺: 一个线程不能去剥夺另一个线程占有的资源
- 请求与保持: 一个线程想请求另外一个资源, 但另一个资源被占有, 当前线程保持不释放已有资源
- 循环等待条件: 在死锁发生时, 两个线程获取资源的顺序构成的环



打破死锁:

- 一般为打破循环等待条件, 让两个线程获取资源的顺序, 不构成环
- 忽略死锁: 鸵鸟算法
- 检测死锁并且恢复
- 通过破除死锁四个必要条件之一，来防止死锁产生







### 缓存IO、直接IO和裸IO

缓存IO与直接IO读写文件依赖于内核文件系统读写文件

缓存IO: 将磁盘数据复制到内核缓冲区, 然后从内核缓冲区复制到用户程序地址空间 (程序读时, 检查内核缓存是否有数据否则从磁盘读取, 写时将数据从用户缓存复制到内核缓存)

直接IO: 用户程序绕过内核缓冲区直接读写文件到用户缓存

裸IO: 绕过内核文件系统直接读写文件







### 阻塞、非阻塞、同步和异步IO

IO 读取数据分为两个阶段: 内核准备好数据, 内核把数据从内核态拷贝到用户态

同步阻塞 IO: 在读取数据两个阶段都会阻塞, 如果没有数据也会阻塞

同步非阻塞 IO: 在内核准备数据阶段不会阻塞, 会通过轮询 read() 方式, 没有数据就返回, 在把数据从内核态拷贝到用户态时阻塞

异步 IO: 用户发起 read() 后, 等待内核把数据拷贝到用户空间后, 通知用户进程





### I/O 多路复用











### select, poll, epoll

都是用于实现IO多路复用, 可以在同一时间监听多个文件描述符的就绪状态

select 和 poll 都是使用线性结构存储, 通过遍历方式获得读写的文件描述符, select使用位图保存文件描述符有最大连接限制, poll是链表结构没有最大连接限制

epoll: 采用红黑树跟踪带检测的文件描述符, 采用事件驱动, 当socket有事件发生事会通过回调函数将其加入事件链表













----------------------

## linux



























----------------------

## 计算机网络



### tcp 与 udp 区别









### tcp 三次握手





### tcp 四次挥手









### SYN 超时，洪泛攻击















### tcp 重传机制











### tcp 拥塞控制















### HTTP和HTTPS的区别









### HTTP方法GET、POST、PUT和PATCH的区别











### OSI七层模型和TCP/IP四层模型的区别













----------------------

## mysql



### 隔离级别

- 读未提交
- 读已提交(rc)
- 可重复读(rr)
- 串行化





### innodb 数据

表空间 -> 分段 -> 分区 -> 页(page)

所有数据都存放在 page (索引, 数据等), 一个 page 16k







### 索引

主键索引(聚簇索引), 辅助索引











### 最左前缀匹配

带头大哥不能缺, 中间兄弟不能少

可以范围索引









### 索引失效

- 左模糊
- 对索引列使用函数
- 对索引表达式计算
- 隐式类型转换
- or 时, 如果有一个不是索引列就会走全表扫描











### mvcc 多版本并发控制

*只作用于 rc, rr*

每张表都有两个隐藏字段: tx_id, roll_id, role_ptr

read view: 结构体

- 活跃事务id列表
- 最小活跃事务id
- 预分配事务id
- 当前事务id

read view 在 rc 下:

当每次 select 时都会, 生成一个 read view, 然后从当前行在找判断当前行是否满足要求, 判断其活跃事务id是否在<最小活跃id, 小于则可以查询该条记录, 否则判断当前行的事务id是否在活跃事务id列表, 如果在就不能读取, 否则, 继续通过role_ptr找下一条记录



在 rr 下:

和 rc 下的查找相同, 但是其 read view 不是动态生成的, 而是沿用上一次 select 时的 read view 从而实现可重复读, 但是当前进行快照读时, 会重新生成一个 read view , 可能产生幻读











### undo log、redo log、binlog

- **undo log（回滚日志）**：是 Innodb 存储引擎层生成的日志，实现了事务中的**原子性**，主要**用于事务回滚和 MVCC**。
- **redo log（重做日志）**：是 Innodb 存储引擎层生成的日志，实现了事务中的**持久性**，主要**用于掉电等故障恢复**；
- **binlog （归档日志）**：是 Server 层生成的日志，主要**用于数据备份和主从复制**；



**Buffer Pool**: 是innodb位于缓存中数据, 主要用于加速加速数据库的读写, 存放页, Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。主要实现就是异步读写磁盘, 当 buffer poll 中有也被修改, 后台线程会定期将脏页写到磁盘



两阶段提交: 当事务写了 redo log (prepare)后, 在mysql server 在写 binlog, 写 binlog 后, innodb 将redo log 标记为 commit, 此时就可理解为数据写入成功, 后台线程会自动将 redo log 落盘





### 手写 sql 























----------------------

## redis

### redis 为什么快

- 完全基于内存的
- 单线程模型: 单线程就不需要考虑到切换线程上下文带来的开销
- 优质的数据结构
- IO 多路复用: epoll 通过红黑树维护监听的文件描述符(socket), 当socket有新事件时会通过回调函数将时间注册到 epoll 维护的事件链表





### redis 线程模型

2.6 版本引入两个线程, 后台处理关闭文件、AOF 刷盘

4.0 新增一个线程用于后台释放redis内存

6.0 正式引入多个 I/O 线程来处理网络请求, 因为当网络硬件设备性能提升后, cpu不会成为瓶颈, 瓶颈就在处理网络请求上





### redis 回收策略













### redis 内存淘汰策略











### redis 持久化











### redis 数据结构

- string: (sds) 动态字符串

- list: 3.2以后只用quicklist, 3.2以前双向链表或压缩链表实现
- hash: listpack
- set: 哈希表, 或(整数数组有条件)
- zset: listpack 或跳表实现
- Bitmap: 用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型
- Stream: 消息队列, 支持 ack 确认消息的模式





















----------------

## others

### 一致性哈希

- 如何分配请求
- 哈希算法
- 一致性哈希问题 : 节点分布不均匀
- 虚拟节点 : 不在将真实节点映射到哈希环, 而是将虚拟节点映射到哈希环, 对于不同的请求, 我们通过算出请求的哈希找到虚拟节点, 在通过虚拟节点找到真实节点

























